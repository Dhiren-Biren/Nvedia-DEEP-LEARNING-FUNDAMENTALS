{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g-atf3gekcgR"
   },
   "source": [
    "# Assessment 1: I can train and deploy a neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_7wkT17FkmU6"
   },
   "source": [
    "At this point, you've worked through a full deep learning workflow. You've loaded a dataset, trained a model, and deployed your model into a simple application. Validate your learning by attempting to replicate that workflow with a new problem.\n",
    "\n",
    "We've included a dataset which consists of two classes:  \n",
    "\n",
    "1) Face: Contains images which include the face of a whale  \n",
    "2) Not Face: Contains images which do not include the face of a whale.  \n",
    "\n",
    "The dataset is located at ```/dli/data/whale/data/train```.\n",
    "\n",
    "Your challenge is:\n",
    "\n",
    "1) Use [DIGITS](/digits) to train a model to identify *new* whale faces with an accuracy of more than 80%.   \n",
    "\n",
    "2) Deploy your model by modifying and saving the python application [submission.py](../../../../edit/tasks/task-assessment/task/submission.py) to return the word \"whale\" if the image contains a whale's face and \"not whale\" if the image does not.  \n",
    "\n",
    "Resources:\n",
    "\n",
    "1) [Train a model](../../task1/task/Train%20a%20Model.ipynb)  \n",
    "2) [New Data as a goal](../../task2/task/New%20Data%20as%20a%20Goal.ipynb)  \n",
    "3) [Deployment](../../task3/task/Deployment.ipynb)  \n",
    "\n",
    "Suggestions: \n",
    "\n",
    "- Use empty code blocks to find out any informantion necessary to solve this problem: eg: ```!ls [directorypath] prints the files in a given directory``` \n",
    "- Executing the first two cells below will run your python script with test images, the first should return \"whale\" and the second should return \"not whale\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YaaY1Vb3o3mC"
   },
   "source": [
    "Start in [DIGITS](/digits/). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0705 01:52:21.151099   500 gpu_memory.cpp:105] GPUMemory::Manager initialized\n",
      "I0705 01:52:21.152132   500 gpu_memory.cpp:107] Total memory: 11996954624, Free: 11802181632, dev_info[0]: total=11996954624 free=11802181632\n",
      "W0705 01:52:21.152192   500 _caffe.cpp:172] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0705 01:52:21.152336   500 _caffe.cpp:173] Use this instead (with the named \"weights\" parameter):\n",
      "W0705 01:52:21.152352   500 _caffe.cpp:175] Net('/dli/data/digits/20200705-013506-0df9/deploy.prototxt', 1, weights='/dli/data/digits/20200705-013506-0df9/snapshot_iter_324.caffemodel')\n",
      "I0705 01:52:21.152678   500 upgrade_proto.cpp:66] Attempting to upgrade input file specified using deprecated input fields: /dli/data/digits/20200705-013506-0df9/deploy.prototxt\n",
      "I0705 01:52:21.152712   500 upgrade_proto.cpp:69] Successfully upgraded file specified using deprecated input fields.\n",
      "W0705 01:52:21.152724   500 upgrade_proto.cpp:71] Note that future Caffe releases will only support input layers and not input fields.\n",
      "I0705 01:52:21.162315   500 net.cpp:79] Initializing net from parameters: \n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"input\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 1\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"conv2\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0.1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"conv3\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0.1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0.1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.005\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0.1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.005\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0.1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc8\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc8\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  inner_product_param {\n",
      "    num_output: 2\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"softmax\"\n",
      "  type: \"Softmax\"\n",
      "  bottom: \"fc8\"\n",
      "  top: \"softmax\"\n",
      "}\n",
      "I0705 01:52:21.162899   500 net.cpp:109] Using FLOAT as default forward math type\n",
      "I0705 01:52:21.162919   500 net.cpp:115] Using FLOAT as default backward math type\n",
      "I0705 01:52:21.162932   500 layer_factory.hpp:172] Creating layer 'input' of type 'Input'\n",
      "I0705 01:52:21.162955   500 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0705 01:52:21.162978   500 net.cpp:199] Created Layer input (0)\n",
      "I0705 01:52:21.163000   500 net.cpp:541] input -> data\n",
      "I0705 01:52:21.163731   500 net.cpp:259] Setting up input\n",
      "I0705 01:52:21.163769   500 net.cpp:266] TEST Top shape for layer 0 'input' 1 3 227 227 (154587)\n",
      "I0705 01:52:21.163787   500 layer_factory.hpp:172] Creating layer 'conv1' of type 'Convolution'\n",
      "I0705 01:52:21.163802   500 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0705 01:52:21.163841   500 net.cpp:199] Created Layer conv1 (1)\n",
      "I0705 01:52:21.163858   500 net.cpp:571] conv1 <- data\n",
      "I0705 01:52:21.163883   500 net.cpp:541] conv1 -> conv1\n",
      "I0705 01:52:21.705766   500 net.cpp:259] Setting up conv1\n",
      "I0705 01:52:21.705824   500 net.cpp:266] TEST Top shape for layer 1 'conv1' 1 96 55 55 (290400)\n",
      "I0705 01:52:21.705868   500 layer_factory.hpp:172] Creating layer 'relu1' of type 'ReLU'\n",
      "I0705 01:52:21.705888   500 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0705 01:52:21.705914   500 net.cpp:199] Created Layer relu1 (2)\n",
      "I0705 01:52:21.705932   500 net.cpp:571] relu1 <- conv1\n",
      "I0705 01:52:21.705947   500 net.cpp:526] relu1 -> conv1 (in-place)\n",
      "I0705 01:52:21.705981   500 net.cpp:259] Setting up relu1\n",
      "I0705 01:52:21.705998   500 net.cpp:266] TEST Top shape for layer 2 'relu1' 1 96 55 55 (290400)\n",
      "I0705 01:52:21.706010   500 layer_factory.hpp:172] Creating layer 'norm1' of type 'LRN'\n",
      "I0705 01:52:21.706027   500 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0705 01:52:21.706064   500 net.cpp:199] Created Layer norm1 (3)\n",
      "I0705 01:52:21.706079   500 net.cpp:571] norm1 <- conv1\n",
      "I0705 01:52:21.706090   500 net.cpp:541] norm1 -> norm1\n",
      "I0705 01:52:21.706154   500 net.cpp:259] Setting up norm1\n",
      "I0705 01:52:21.706176   500 net.cpp:266] TEST Top shape for layer 3 'norm1' 1 96 55 55 (290400)\n",
      "I0705 01:52:21.706189   500 layer_factory.hpp:172] Creating layer 'pool1' of type 'Pooling'\n",
      "I0705 01:52:21.706205   500 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0705 01:52:21.706260   500 net.cpp:199] Created Layer pool1 (4)\n",
      "I0705 01:52:21.706279   500 net.cpp:571] pool1 <- norm1\n",
      "I0705 01:52:21.706291   500 net.cpp:541] pool1 -> pool1\n",
      "I0705 01:52:21.706362   500 net.cpp:259] Setting up pool1\n",
      "I0705 01:52:21.706399   500 net.cpp:266] TEST Top shape for layer 4 'pool1' 1 96 27 27 (69984)\n",
      "I0705 01:52:21.706419   500 layer_factory.hpp:172] Creating layer 'conv2' of type 'Convolution'\n",
      "I0705 01:52:21.706431   500 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0705 01:52:21.706468   500 net.cpp:199] Created Layer conv2 (5)\n",
      "I0705 01:52:21.706482   500 net.cpp:571] conv2 <- pool1\n",
      "I0705 01:52:21.706496   500 net.cpp:541] conv2 -> conv2\n",
      "I0705 01:52:21.713071   500 net.cpp:259] Setting up conv2\n",
      "I0705 01:52:21.713102   500 net.cpp:266] TEST Top shape for layer 5 'conv2' 1 256 27 27 (186624)\n",
      "I0705 01:52:21.713129   500 layer_factory.hpp:172] Creating layer 'relu2' of type 'ReLU'\n",
      "I0705 01:52:21.713147   500 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0705 01:52:21.713157   500 net.cpp:199] Created Layer relu2 (6)\n",
      "I0705 01:52:21.713168   500 net.cpp:571] relu2 <- conv2\n",
      "I0705 01:52:21.713176   500 net.cpp:526] relu2 -> conv2 (in-place)\n",
      "I0705 01:52:21.713192   500 net.cpp:259] Setting up relu2\n",
      "I0705 01:52:21.713205   500 net.cpp:266] TEST Top shape for layer 6 'relu2' 1 256 27 27 (186624)\n",
      "I0705 01:52:21.713214   500 layer_factory.hpp:172] Creating layer 'norm2' of type 'LRN'\n",
      "I0705 01:52:21.713225   500 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0705 01:52:21.713238   500 net.cpp:199] Created Layer norm2 (7)\n",
      "I0705 01:52:21.713249   500 net.cpp:571] norm2 <- conv2\n",
      "I0705 01:52:21.713256   500 net.cpp:541] norm2 -> norm2\n",
      "I0705 01:52:21.713305   500 net.cpp:259] Setting up norm2\n",
      "I0705 01:52:21.713322   500 net.cpp:266] TEST Top shape for layer 7 'norm2' 1 256 27 27 (186624)\n",
      "I0705 01:52:21.713331   500 layer_factory.hpp:172] Creating layer 'pool2' of type 'Pooling'\n",
      "I0705 01:52:21.713343   500 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0705 01:52:21.713354   500 net.cpp:199] Created Layer pool2 (8)\n",
      "I0705 01:52:21.713366   500 net.cpp:571] pool2 <- norm2\n",
      "I0705 01:52:21.713373   500 net.cpp:541] pool2 -> pool2\n",
      "I0705 01:52:21.713420   500 net.cpp:259] Setting up pool2\n",
      "I0705 01:52:21.713436   500 net.cpp:266] TEST Top shape for layer 8 'pool2' 1 256 13 13 (43264)\n",
      "I0705 01:52:21.713446   500 layer_factory.hpp:172] Creating layer 'conv3' of type 'Convolution'\n",
      "I0705 01:52:21.713459   500 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0705 01:52:21.713474   500 net.cpp:199] Created Layer conv3 (9)\n",
      "I0705 01:52:21.713485   500 net.cpp:571] conv3 <- pool2\n",
      "I0705 01:52:21.713492   500 net.cpp:541] conv3 -> conv3\n",
      "I0705 01:52:21.729205   500 net.cpp:259] Setting up conv3\n",
      "I0705 01:52:21.729259   500 net.cpp:266] TEST Top shape for layer 9 'conv3' 1 384 13 13 (64896)\n",
      "I0705 01:52:21.729295   500 layer_factory.hpp:172] Creating layer 'relu3' of type 'ReLU'\n",
      "I0705 01:52:21.729311   500 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0705 01:52:21.729336   500 net.cpp:199] Created Layer relu3 (10)\n",
      "I0705 01:52:21.729355   500 net.cpp:571] relu3 <- conv3\n",
      "I0705 01:52:21.729369   500 net.cpp:526] relu3 -> conv3 (in-place)\n",
      "I0705 01:52:21.729394   500 net.cpp:259] Setting up relu3\n",
      "I0705 01:52:21.729413   500 net.cpp:266] TEST Top shape for layer 10 'relu3' 1 384 13 13 (64896)\n",
      "I0705 01:52:21.729425   500 layer_factory.hpp:172] Creating layer 'conv4' of type 'Convolution'\n",
      "I0705 01:52:21.729441   500 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0705 01:52:21.729470   500 net.cpp:199] Created Layer conv4 (11)\n",
      "I0705 01:52:21.729482   500 net.cpp:571] conv4 <- conv3\n",
      "I0705 01:52:21.729496   500 net.cpp:541] conv4 -> conv4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0705 01:52:21.742269   500 net.cpp:259] Setting up conv4\n",
      "I0705 01:52:21.742308   500 net.cpp:266] TEST Top shape for layer 11 'conv4' 1 384 13 13 (64896)\n",
      "I0705 01:52:21.742370   500 layer_factory.hpp:172] Creating layer 'relu4' of type 'ReLU'\n",
      "I0705 01:52:21.742403   500 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0705 01:52:21.742419   500 net.cpp:199] Created Layer relu4 (12)\n",
      "I0705 01:52:21.742436   500 net.cpp:571] relu4 <- conv4\n",
      "I0705 01:52:21.742451   500 net.cpp:526] relu4 -> conv4 (in-place)\n",
      "I0705 01:52:21.742473   500 net.cpp:259] Setting up relu4\n",
      "I0705 01:52:21.742492   500 net.cpp:266] TEST Top shape for layer 12 'relu4' 1 384 13 13 (64896)\n",
      "I0705 01:52:21.742511   500 layer_factory.hpp:172] Creating layer 'conv5' of type 'Convolution'\n",
      "I0705 01:52:21.742528   500 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0705 01:52:21.742558   500 net.cpp:199] Created Layer conv5 (13)\n",
      "I0705 01:52:21.742573   500 net.cpp:571] conv5 <- conv4\n",
      "I0705 01:52:21.742585   500 net.cpp:541] conv5 -> conv5\n",
      "I0705 01:52:21.750697   500 net.cpp:259] Setting up conv5\n",
      "I0705 01:52:21.750738   500 net.cpp:266] TEST Top shape for layer 13 'conv5' 1 256 13 13 (43264)\n",
      "I0705 01:52:21.750773   500 layer_factory.hpp:172] Creating layer 'relu5' of type 'ReLU'\n",
      "I0705 01:52:21.750797   500 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0705 01:52:21.750820   500 net.cpp:199] Created Layer relu5 (14)\n",
      "I0705 01:52:21.750836   500 net.cpp:571] relu5 <- conv5\n",
      "I0705 01:52:21.750849   500 net.cpp:526] relu5 -> conv5 (in-place)\n",
      "I0705 01:52:21.750867   500 net.cpp:259] Setting up relu5\n",
      "I0705 01:52:21.750881   500 net.cpp:266] TEST Top shape for layer 14 'relu5' 1 256 13 13 (43264)\n",
      "I0705 01:52:21.750895   500 layer_factory.hpp:172] Creating layer 'pool5' of type 'Pooling'\n",
      "I0705 01:52:21.750910   500 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0705 01:52:21.750931   500 net.cpp:199] Created Layer pool5 (15)\n",
      "I0705 01:52:21.750941   500 net.cpp:571] pool5 <- conv5\n",
      "I0705 01:52:21.750953   500 net.cpp:541] pool5 -> pool5\n",
      "I0705 01:52:21.751032   500 net.cpp:259] Setting up pool5\n",
      "I0705 01:52:21.751057   500 net.cpp:266] TEST Top shape for layer 15 'pool5' 1 256 6 6 (9216)\n",
      "I0705 01:52:21.751076   500 layer_factory.hpp:172] Creating layer 'fc6' of type 'InnerProduct'\n",
      "I0705 01:52:21.751094   500 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0705 01:52:21.751121   500 net.cpp:199] Created Layer fc6 (16)\n",
      "I0705 01:52:21.751142   500 net.cpp:571] fc6 <- pool5\n",
      "I0705 01:52:21.751159   500 net.cpp:541] fc6 -> fc6\n",
      "I0705 01:52:22.435168   500 net.cpp:259] Setting up fc6\n",
      "I0705 01:52:22.435220   500 net.cpp:266] TEST Top shape for layer 16 'fc6' 1 4096 (4096)\n",
      "I0705 01:52:22.435254   500 layer_factory.hpp:172] Creating layer 'relu6' of type 'ReLU'\n",
      "I0705 01:52:22.435276   500 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0705 01:52:22.435302   500 net.cpp:199] Created Layer relu6 (17)\n",
      "I0705 01:52:22.435320   500 net.cpp:571] relu6 <- fc6\n",
      "I0705 01:52:22.435343   500 net.cpp:526] relu6 -> fc6 (in-place)\n",
      "I0705 01:52:22.435364   500 net.cpp:259] Setting up relu6\n",
      "I0705 01:52:22.435379   500 net.cpp:266] TEST Top shape for layer 17 'relu6' 1 4096 (4096)\n",
      "I0705 01:52:22.435386   500 layer_factory.hpp:172] Creating layer 'drop6' of type 'Dropout'\n",
      "I0705 01:52:22.435400   500 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0705 01:52:22.435421   500 net.cpp:199] Created Layer drop6 (18)\n",
      "I0705 01:52:22.435432   500 net.cpp:571] drop6 <- fc6\n",
      "I0705 01:52:22.435441   500 net.cpp:526] drop6 -> fc6 (in-place)\n",
      "I0705 01:52:22.469182   500 net.cpp:259] Setting up drop6\n",
      "I0705 01:52:22.469236   500 net.cpp:266] TEST Top shape for layer 18 'drop6' 1 4096 (4096)\n",
      "I0705 01:52:22.469260   500 layer_factory.hpp:172] Creating layer 'fc7' of type 'InnerProduct'\n",
      "I0705 01:52:22.469276   500 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0705 01:52:22.469306   500 net.cpp:199] Created Layer fc7 (19)\n",
      "I0705 01:52:22.469363   500 net.cpp:571] fc7 <- fc6\n",
      "I0705 01:52:22.469383   500 net.cpp:541] fc7 -> fc7\n",
      "I0705 01:52:22.775528   500 net.cpp:259] Setting up fc7\n",
      "I0705 01:52:22.775584   500 net.cpp:266] TEST Top shape for layer 19 'fc7' 1 4096 (4096)\n",
      "I0705 01:52:22.775614   500 layer_factory.hpp:172] Creating layer 'relu7' of type 'ReLU'\n",
      "I0705 01:52:22.775631   500 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0705 01:52:22.775651   500 net.cpp:199] Created Layer relu7 (20)\n",
      "I0705 01:52:22.775669   500 net.cpp:571] relu7 <- fc7\n",
      "I0705 01:52:22.775684   500 net.cpp:526] relu7 -> fc7 (in-place)\n",
      "I0705 01:52:22.775712   500 net.cpp:259] Setting up relu7\n",
      "I0705 01:52:22.775729   500 net.cpp:266] TEST Top shape for layer 20 'relu7' 1 4096 (4096)\n",
      "I0705 01:52:22.775748   500 layer_factory.hpp:172] Creating layer 'drop7' of type 'Dropout'\n",
      "I0705 01:52:22.775758   500 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0705 01:52:22.775784   500 net.cpp:199] Created Layer drop7 (21)\n",
      "I0705 01:52:22.775799   500 net.cpp:571] drop7 <- fc7\n",
      "I0705 01:52:22.775812   500 net.cpp:526] drop7 -> fc7 (in-place)\n",
      "I0705 01:52:22.809585   500 net.cpp:259] Setting up drop7\n",
      "I0705 01:52:22.809650   500 net.cpp:266] TEST Top shape for layer 21 'drop7' 1 4096 (4096)\n",
      "I0705 01:52:22.809667   500 layer_factory.hpp:172] Creating layer 'fc8' of type 'InnerProduct'\n",
      "I0705 01:52:22.809692   500 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0705 01:52:22.809725   500 net.cpp:199] Created Layer fc8 (22)\n",
      "I0705 01:52:22.809742   500 net.cpp:571] fc8 <- fc7\n",
      "I0705 01:52:22.809758   500 net.cpp:541] fc8 -> fc8\n",
      "I0705 01:52:22.810019   500 net.cpp:259] Setting up fc8\n",
      "I0705 01:52:22.810041   500 net.cpp:266] TEST Top shape for layer 22 'fc8' 1 2 (2)\n",
      "I0705 01:52:22.810062   500 layer_factory.hpp:172] Creating layer 'softmax' of type 'Softmax'\n",
      "I0705 01:52:22.810079   500 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0705 01:52:22.810104   500 net.cpp:199] Created Layer softmax (23)\n",
      "I0705 01:52:22.810118   500 net.cpp:571] softmax <- fc8\n",
      "I0705 01:52:22.810130   500 net.cpp:541] softmax -> softmax\n",
      "I0705 01:52:22.810214   500 net.cpp:259] Setting up softmax\n",
      "I0705 01:52:22.810233   500 net.cpp:266] TEST Top shape for layer 23 'softmax' 1 2 (2)\n",
      "I0705 01:52:22.810245   500 net.cpp:337] softmax does not need backward computation.\n",
      "I0705 01:52:22.810264   500 net.cpp:337] fc8 does not need backward computation.\n",
      "I0705 01:52:22.810274   500 net.cpp:337] drop7 does not need backward computation.\n",
      "I0705 01:52:22.810289   500 net.cpp:337] relu7 does not need backward computation.\n",
      "I0705 01:52:22.810300   500 net.cpp:337] fc7 does not need backward computation.\n",
      "I0705 01:52:22.810312   500 net.cpp:337] drop6 does not need backward computation.\n",
      "I0705 01:52:22.810328   500 net.cpp:337] relu6 does not need backward computation.\n",
      "I0705 01:52:22.810339   500 net.cpp:337] fc6 does not need backward computation.\n",
      "I0705 01:52:22.810357   500 net.cpp:337] pool5 does not need backward computation.\n",
      "I0705 01:52:22.810369   500 net.cpp:337] relu5 does not need backward computation.\n",
      "I0705 01:52:22.810401   500 net.cpp:337] conv5 does not need backward computation.\n",
      "I0705 01:52:22.810420   500 net.cpp:337] relu4 does not need backward computation.\n",
      "I0705 01:52:22.810431   500 net.cpp:337] conv4 does not need backward computation.\n",
      "I0705 01:52:22.810441   500 net.cpp:337] relu3 does not need backward computation.\n",
      "I0705 01:52:22.810456   500 net.cpp:337] conv3 does not need backward computation.\n",
      "I0705 01:52:22.810468   500 net.cpp:337] pool2 does not need backward computation.\n",
      "I0705 01:52:22.810484   500 net.cpp:337] norm2 does not need backward computation.\n",
      "I0705 01:52:22.810495   500 net.cpp:337] relu2 does not need backward computation.\n",
      "I0705 01:52:22.810505   500 net.cpp:337] conv2 does not need backward computation.\n",
      "I0705 01:52:22.810523   500 net.cpp:337] pool1 does not need backward computation.\n",
      "I0705 01:52:22.810572   500 net.cpp:337] norm1 does not need backward computation.\n",
      "I0705 01:52:22.810585   500 net.cpp:337] relu1 does not need backward computation.\n",
      "I0705 01:52:22.810603   500 net.cpp:337] conv1 does not need backward computation.\n",
      "I0705 01:52:22.810616   500 net.cpp:337] input does not need backward computation.\n",
      "I0705 01:52:22.810626   500 net.cpp:379] This network produces output softmax\n",
      "I0705 01:52:22.810667   500 net.cpp:402] Top memory (TEST) required for data: 8315264 diff: 8315264\n",
      "I0705 01:52:22.810683   500 net.cpp:405] Bottom memory (TEST) required for data: 8315256 diff: 8315256\n",
      "I0705 01:52:22.810693   500 net.cpp:408] Shared (in-place) memory (TEST) by data: 2665856 diff: 2665856\n",
      "I0705 01:52:22.810703   500 net.cpp:411] Parameters memory (TEST) required for data: 227505672 diff: 227505672\n",
      "I0705 01:52:22.810719   500 net.cpp:414] Parameters shared memory (TEST) by data: 0 diff: 0\n",
      "I0705 01:52:22.810729   500 net.cpp:420] Network initialization done.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0705 01:52:22.925817   500 net.cpp:1129] Ignoring source layer train-data\n",
      "I0705 01:52:22.925860   500 net.cpp:1137] Copying source layer conv1 Type:Convolution #blobs=2\n",
      "I0705 01:52:22.925978   500 net.cpp:1137] Copying source layer relu1 Type:ReLU #blobs=0\n",
      "I0705 01:52:22.925997   500 net.cpp:1137] Copying source layer norm1 Type:LRN #blobs=0\n",
      "I0705 01:52:22.926007   500 net.cpp:1137] Copying source layer pool1 Type:Pooling #blobs=0\n",
      "I0705 01:52:22.926024   500 net.cpp:1137] Copying source layer conv2 Type:Convolution #blobs=2\n",
      "I0705 01:52:22.926240   500 net.cpp:1137] Copying source layer relu2 Type:ReLU #blobs=0\n",
      "I0705 01:52:22.926256   500 net.cpp:1137] Copying source layer norm2 Type:LRN #blobs=0\n",
      "I0705 01:52:22.926270   500 net.cpp:1137] Copying source layer pool2 Type:Pooling #blobs=0\n",
      "I0705 01:52:22.926276   500 net.cpp:1137] Copying source layer conv3 Type:Convolution #blobs=2\n",
      "I0705 01:52:22.926770   500 net.cpp:1137] Copying source layer relu3 Type:ReLU #blobs=0\n",
      "I0705 01:52:22.926789   500 net.cpp:1137] Copying source layer conv4 Type:Convolution #blobs=2\n",
      "I0705 01:52:22.927148   500 net.cpp:1137] Copying source layer relu4 Type:ReLU #blobs=0\n",
      "I0705 01:52:22.927165   500 net.cpp:1137] Copying source layer conv5 Type:Convolution #blobs=2\n",
      "I0705 01:52:22.927431   500 net.cpp:1137] Copying source layer relu5 Type:ReLU #blobs=0\n",
      "I0705 01:52:22.927448   500 net.cpp:1137] Copying source layer pool5 Type:Pooling #blobs=0\n",
      "I0705 01:52:22.927457   500 net.cpp:1137] Copying source layer fc6 Type:InnerProduct #blobs=2\n",
      "I0705 01:52:22.945760   500 net.cpp:1137] Copying source layer relu6 Type:ReLU #blobs=0\n",
      "I0705 01:52:22.945791   500 net.cpp:1137] Copying source layer drop6 Type:Dropout #blobs=0\n",
      "I0705 01:52:22.945806   500 net.cpp:1137] Copying source layer fc7 Type:InnerProduct #blobs=2\n",
      "I0705 01:52:22.953969   500 net.cpp:1137] Copying source layer relu7 Type:ReLU #blobs=0\n",
      "I0705 01:52:22.953999   500 net.cpp:1137] Copying source layer drop7 Type:Dropout #blobs=0\n",
      "I0705 01:52:22.954012   500 net.cpp:1137] Copying source layer fc8 Type:InnerProduct #blobs=2\n",
      "I0705 01:52:22.954066   500 net.cpp:1129] Ignoring source layer loss\n",
      "whale\n"
     ]
    }
   ],
   "source": [
    "!python submission.py '/dli/data/whale/data/train/face/w_1.jpg'  #This should return \"whale\" at the very bottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0705 01:52:32.587064   515 gpu_memory.cpp:105] GPUMemory::Manager initialized\n",
      "I0705 01:52:32.588135   515 gpu_memory.cpp:107] Total memory: 11996954624, Free: 11802181632, dev_info[0]: total=11996954624 free=11802181632\n",
      "W0705 01:52:32.588201   515 _caffe.cpp:172] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0705 01:52:32.588333   515 _caffe.cpp:173] Use this instead (with the named \"weights\" parameter):\n",
      "W0705 01:52:32.588356   515 _caffe.cpp:175] Net('/dli/data/digits/20200705-013506-0df9/deploy.prototxt', 1, weights='/dli/data/digits/20200705-013506-0df9/snapshot_iter_324.caffemodel')\n",
      "I0705 01:52:32.588692   515 upgrade_proto.cpp:66] Attempting to upgrade input file specified using deprecated input fields: /dli/data/digits/20200705-013506-0df9/deploy.prototxt\n",
      "I0705 01:52:32.588726   515 upgrade_proto.cpp:69] Successfully upgraded file specified using deprecated input fields.\n",
      "W0705 01:52:32.588742   515 upgrade_proto.cpp:71] Note that future Caffe releases will only support input layers and not input fields.\n",
      "I0705 01:52:32.599362   515 net.cpp:79] Initializing net from parameters: \n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"input\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 1\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"conv2\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0.1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"conv3\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0.1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0.1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.005\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0.1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.005\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0.1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc8\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc8\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  inner_product_param {\n",
      "    num_output: 2\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"softmax\"\n",
      "  type: \"Softmax\"\n",
      "  bottom: \"fc8\"\n",
      "  top: \"softmax\"\n",
      "}\n",
      "I0705 01:52:32.599777   515 net.cpp:109] Using FLOAT as default forward math type\n",
      "I0705 01:52:32.599797   515 net.cpp:115] Using FLOAT as default backward math type\n",
      "I0705 01:52:32.599812   515 layer_factory.hpp:172] Creating layer 'input' of type 'Input'\n",
      "I0705 01:52:32.599830   515 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0705 01:52:32.599860   515 net.cpp:199] Created Layer input (0)\n",
      "I0705 01:52:32.599875   515 net.cpp:541] input -> data\n",
      "I0705 01:52:32.600649   515 net.cpp:259] Setting up input\n",
      "I0705 01:52:32.600682   515 net.cpp:266] TEST Top shape for layer 0 'input' 1 3 227 227 (154587)\n",
      "I0705 01:52:32.600704   515 layer_factory.hpp:172] Creating layer 'conv1' of type 'Convolution'\n",
      "I0705 01:52:32.600718   515 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0705 01:52:32.600749   515 net.cpp:199] Created Layer conv1 (1)\n",
      "I0705 01:52:32.600761   515 net.cpp:571] conv1 <- data\n",
      "I0705 01:52:32.600770   515 net.cpp:541] conv1 -> conv1\n",
      "I0705 01:52:33.135251   515 net.cpp:259] Setting up conv1\n",
      "I0705 01:52:33.135305   515 net.cpp:266] TEST Top shape for layer 1 'conv1' 1 96 55 55 (290400)\n",
      "I0705 01:52:33.135347   515 layer_factory.hpp:172] Creating layer 'relu1' of type 'ReLU'\n",
      "I0705 01:52:33.135371   515 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0705 01:52:33.135401   515 net.cpp:199] Created Layer relu1 (2)\n",
      "I0705 01:52:33.135418   515 net.cpp:571] relu1 <- conv1\n",
      "I0705 01:52:33.135432   515 net.cpp:526] relu1 -> conv1 (in-place)\n",
      "I0705 01:52:33.135466   515 net.cpp:259] Setting up relu1\n",
      "I0705 01:52:33.135483   515 net.cpp:266] TEST Top shape for layer 2 'relu1' 1 96 55 55 (290400)\n",
      "I0705 01:52:33.135494   515 layer_factory.hpp:172] Creating layer 'norm1' of type 'LRN'\n",
      "I0705 01:52:33.135511   515 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0705 01:52:33.135543   515 net.cpp:199] Created Layer norm1 (3)\n",
      "I0705 01:52:33.135557   515 net.cpp:571] norm1 <- conv1\n",
      "I0705 01:52:33.135574   515 net.cpp:541] norm1 -> norm1\n",
      "I0705 01:52:33.135635   515 net.cpp:259] Setting up norm1\n",
      "I0705 01:52:33.135653   515 net.cpp:266] TEST Top shape for layer 3 'norm1' 1 96 55 55 (290400)\n",
      "I0705 01:52:33.135659   515 layer_factory.hpp:172] Creating layer 'pool1' of type 'Pooling'\n",
      "I0705 01:52:33.135668   515 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0705 01:52:33.135713   515 net.cpp:199] Created Layer pool1 (4)\n",
      "I0705 01:52:33.135726   515 net.cpp:571] pool1 <- norm1\n",
      "I0705 01:52:33.135732   515 net.cpp:541] pool1 -> pool1\n",
      "I0705 01:52:33.135792   515 net.cpp:259] Setting up pool1\n",
      "I0705 01:52:33.135807   515 net.cpp:266] TEST Top shape for layer 4 'pool1' 1 96 27 27 (69984)\n",
      "I0705 01:52:33.135816   515 layer_factory.hpp:172] Creating layer 'conv2' of type 'Convolution'\n",
      "I0705 01:52:33.135828   515 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0705 01:52:33.135846   515 net.cpp:199] Created Layer conv2 (5)\n",
      "I0705 01:52:33.135857   515 net.cpp:571] conv2 <- pool1\n",
      "I0705 01:52:33.135864   515 net.cpp:541] conv2 -> conv2\n",
      "I0705 01:52:33.142369   515 net.cpp:259] Setting up conv2\n",
      "I0705 01:52:33.142418   515 net.cpp:266] TEST Top shape for layer 5 'conv2' 1 256 27 27 (186624)\n",
      "I0705 01:52:33.142433   515 layer_factory.hpp:172] Creating layer 'relu2' of type 'ReLU'\n",
      "I0705 01:52:33.142447   515 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0705 01:52:33.142457   515 net.cpp:199] Created Layer relu2 (6)\n",
      "I0705 01:52:33.142469   515 net.cpp:571] relu2 <- conv2\n",
      "I0705 01:52:33.142477   515 net.cpp:526] relu2 -> conv2 (in-place)\n",
      "I0705 01:52:33.142493   515 net.cpp:259] Setting up relu2\n",
      "I0705 01:52:33.142508   515 net.cpp:266] TEST Top shape for layer 6 'relu2' 1 256 27 27 (186624)\n",
      "I0705 01:52:33.142514   515 layer_factory.hpp:172] Creating layer 'norm2' of type 'LRN'\n",
      "I0705 01:52:33.142524   515 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0705 01:52:33.142539   515 net.cpp:199] Created Layer norm2 (7)\n",
      "I0705 01:52:33.142549   515 net.cpp:571] norm2 <- conv2\n",
      "I0705 01:52:33.142556   515 net.cpp:541] norm2 -> norm2\n",
      "I0705 01:52:33.142608   515 net.cpp:259] Setting up norm2\n",
      "I0705 01:52:33.142623   515 net.cpp:266] TEST Top shape for layer 7 'norm2' 1 256 27 27 (186624)\n",
      "I0705 01:52:33.142632   515 layer_factory.hpp:172] Creating layer 'pool2' of type 'Pooling'\n",
      "I0705 01:52:33.142643   515 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0705 01:52:33.142655   515 net.cpp:199] Created Layer pool2 (8)\n",
      "I0705 01:52:33.142666   515 net.cpp:571] pool2 <- norm2\n",
      "I0705 01:52:33.142673   515 net.cpp:541] pool2 -> pool2\n",
      "I0705 01:52:33.142721   515 net.cpp:259] Setting up pool2\n",
      "I0705 01:52:33.142736   515 net.cpp:266] TEST Top shape for layer 8 'pool2' 1 256 13 13 (43264)\n",
      "I0705 01:52:33.142745   515 layer_factory.hpp:172] Creating layer 'conv3' of type 'Convolution'\n",
      "I0705 01:52:33.142752   515 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0705 01:52:33.142771   515 net.cpp:199] Created Layer conv3 (9)\n",
      "I0705 01:52:33.142781   515 net.cpp:571] conv3 <- pool2\n",
      "I0705 01:52:33.142788   515 net.cpp:541] conv3 -> conv3\n",
      "I0705 01:52:33.158509   515 net.cpp:259] Setting up conv3\n",
      "I0705 01:52:33.158553   515 net.cpp:266] TEST Top shape for layer 9 'conv3' 1 384 13 13 (64896)\n",
      "I0705 01:52:33.158584   515 layer_factory.hpp:172] Creating layer 'relu3' of type 'ReLU'\n",
      "I0705 01:52:33.158601   515 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0705 01:52:33.158618   515 net.cpp:199] Created Layer relu3 (10)\n",
      "I0705 01:52:33.158634   515 net.cpp:571] relu3 <- conv3\n",
      "I0705 01:52:33.158648   515 net.cpp:526] relu3 -> conv3 (in-place)\n",
      "I0705 01:52:33.158672   515 net.cpp:259] Setting up relu3\n",
      "I0705 01:52:33.158690   515 net.cpp:266] TEST Top shape for layer 10 'relu3' 1 384 13 13 (64896)\n",
      "I0705 01:52:33.158702   515 layer_factory.hpp:172] Creating layer 'conv4' of type 'Convolution'\n",
      "I0705 01:52:33.158718   515 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0705 01:52:33.158746   515 net.cpp:199] Created Layer conv4 (11)\n",
      "I0705 01:52:33.158758   515 net.cpp:571] conv4 <- conv3\n",
      "I0705 01:52:33.158771   515 net.cpp:541] conv4 -> conv4\n",
      "I0705 01:52:33.171666   515 net.cpp:259] Setting up conv4\n",
      "I0705 01:52:33.171720   515 net.cpp:266] TEST Top shape for layer 11 'conv4' 1 384 13 13 (64896)\n",
      "I0705 01:52:33.171789   515 layer_factory.hpp:172] Creating layer 'relu4' of type 'ReLU'\n",
      "I0705 01:52:33.171808   515 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0705 01:52:33.171834   515 net.cpp:199] Created Layer relu4 (12)\n",
      "I0705 01:52:33.171851   515 net.cpp:571] relu4 <- conv4\n",
      "I0705 01:52:33.171866   515 net.cpp:526] relu4 -> conv4 (in-place)\n",
      "I0705 01:52:33.171888   515 net.cpp:259] Setting up relu4\n",
      "I0705 01:52:33.171906   515 net.cpp:266] TEST Top shape for layer 12 'relu4' 1 384 13 13 (64896)\n",
      "I0705 01:52:33.171923   515 layer_factory.hpp:172] Creating layer 'conv5' of type 'Convolution'\n",
      "I0705 01:52:33.171936   515 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0705 01:52:33.171967   515 net.cpp:199] Created Layer conv5 (13)\n",
      "I0705 01:52:33.171980   515 net.cpp:571] conv5 <- conv4\n",
      "I0705 01:52:33.171993   515 net.cpp:541] conv5 -> conv5\n",
      "I0705 01:52:33.180649   515 net.cpp:259] Setting up conv5\n",
      "I0705 01:52:33.180697   515 net.cpp:266] TEST Top shape for layer 13 'conv5' 1 256 13 13 (43264)\n",
      "I0705 01:52:33.180732   515 layer_factory.hpp:172] Creating layer 'relu5' of type 'ReLU'\n",
      "I0705 01:52:33.180748   515 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0705 01:52:33.180768   515 net.cpp:199] Created Layer relu5 (14)\n",
      "I0705 01:52:33.180781   515 net.cpp:571] relu5 <- conv5\n",
      "I0705 01:52:33.180795   515 net.cpp:526] relu5 -> conv5 (in-place)\n",
      "I0705 01:52:33.180814   515 net.cpp:259] Setting up relu5\n",
      "I0705 01:52:33.180825   515 net.cpp:266] TEST Top shape for layer 14 'relu5' 1 256 13 13 (43264)\n",
      "I0705 01:52:33.180837   515 layer_factory.hpp:172] Creating layer 'pool5' of type 'Pooling'\n",
      "I0705 01:52:33.180848   515 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0705 01:52:33.180866   515 net.cpp:199] Created Layer pool5 (15)\n",
      "I0705 01:52:33.180877   515 net.cpp:571] pool5 <- conv5\n",
      "I0705 01:52:33.180883   515 net.cpp:541] pool5 -> pool5\n",
      "I0705 01:52:33.180949   515 net.cpp:259] Setting up pool5\n",
      "I0705 01:52:33.180966   515 net.cpp:266] TEST Top shape for layer 15 'pool5' 1 256 6 6 (9216)\n",
      "I0705 01:52:33.180979   515 layer_factory.hpp:172] Creating layer 'fc6' of type 'InnerProduct'\n",
      "I0705 01:52:33.180999   515 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0705 01:52:33.181023   515 net.cpp:199] Created Layer fc6 (16)\n",
      "I0705 01:52:33.181036   515 net.cpp:571] fc6 <- pool5\n",
      "I0705 01:52:33.181043   515 net.cpp:541] fc6 -> fc6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0705 01:52:33.860132   515 net.cpp:259] Setting up fc6\n",
      "I0705 01:52:33.860183   515 net.cpp:266] TEST Top shape for layer 16 'fc6' 1 4096 (4096)\n",
      "I0705 01:52:33.860211   515 layer_factory.hpp:172] Creating layer 'relu6' of type 'ReLU'\n",
      "I0705 01:52:33.860229   515 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0705 01:52:33.860249   515 net.cpp:199] Created Layer relu6 (17)\n",
      "I0705 01:52:33.860265   515 net.cpp:571] relu6 <- fc6\n",
      "I0705 01:52:33.860287   515 net.cpp:526] relu6 -> fc6 (in-place)\n",
      "I0705 01:52:33.860314   515 net.cpp:259] Setting up relu6\n",
      "I0705 01:52:33.860330   515 net.cpp:266] TEST Top shape for layer 17 'relu6' 1 4096 (4096)\n",
      "I0705 01:52:33.860342   515 layer_factory.hpp:172] Creating layer 'drop6' of type 'Dropout'\n",
      "I0705 01:52:33.860358   515 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0705 01:52:33.860379   515 net.cpp:199] Created Layer drop6 (18)\n",
      "I0705 01:52:33.860394   515 net.cpp:571] drop6 <- fc6\n",
      "I0705 01:52:33.860404   515 net.cpp:526] drop6 -> fc6 (in-place)\n",
      "I0705 01:52:33.893998   515 net.cpp:259] Setting up drop6\n",
      "I0705 01:52:33.894049   515 net.cpp:266] TEST Top shape for layer 18 'drop6' 1 4096 (4096)\n",
      "I0705 01:52:33.894074   515 layer_factory.hpp:172] Creating layer 'fc7' of type 'InnerProduct'\n",
      "I0705 01:52:33.894095   515 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0705 01:52:33.894125   515 net.cpp:199] Created Layer fc7 (19)\n",
      "I0705 01:52:33.894173   515 net.cpp:571] fc7 <- fc6\n",
      "I0705 01:52:33.894189   515 net.cpp:541] fc7 -> fc7\n",
      "I0705 01:52:34.196501   515 net.cpp:259] Setting up fc7\n",
      "I0705 01:52:34.196558   515 net.cpp:266] TEST Top shape for layer 19 'fc7' 1 4096 (4096)\n",
      "I0705 01:52:34.196594   515 layer_factory.hpp:172] Creating layer 'relu7' of type 'ReLU'\n",
      "I0705 01:52:34.196614   515 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0705 01:52:34.196627   515 net.cpp:199] Created Layer relu7 (20)\n",
      "I0705 01:52:34.196640   515 net.cpp:571] relu7 <- fc7\n",
      "I0705 01:52:34.196650   515 net.cpp:526] relu7 -> fc7 (in-place)\n",
      "I0705 01:52:34.196672   515 net.cpp:259] Setting up relu7\n",
      "I0705 01:52:34.196684   515 net.cpp:266] TEST Top shape for layer 20 'relu7' 1 4096 (4096)\n",
      "I0705 01:52:34.196693   515 layer_factory.hpp:172] Creating layer 'drop7' of type 'Dropout'\n",
      "I0705 01:52:34.196705   515 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0705 01:52:34.196718   515 net.cpp:199] Created Layer drop7 (21)\n",
      "I0705 01:52:34.196729   515 net.cpp:571] drop7 <- fc7\n",
      "I0705 01:52:34.196738   515 net.cpp:526] drop7 -> fc7 (in-place)\n",
      "I0705 01:52:34.230512   515 net.cpp:259] Setting up drop7\n",
      "I0705 01:52:34.230554   515 net.cpp:266] TEST Top shape for layer 21 'drop7' 1 4096 (4096)\n",
      "I0705 01:52:34.230571   515 layer_factory.hpp:172] Creating layer 'fc8' of type 'InnerProduct'\n",
      "I0705 01:52:34.230585   515 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0705 01:52:34.230607   515 net.cpp:199] Created Layer fc8 (22)\n",
      "I0705 01:52:34.230620   515 net.cpp:571] fc8 <- fc7\n",
      "I0705 01:52:34.230638   515 net.cpp:541] fc8 -> fc8\n",
      "I0705 01:52:34.230882   515 net.cpp:259] Setting up fc8\n",
      "I0705 01:52:34.230897   515 net.cpp:266] TEST Top shape for layer 22 'fc8' 1 2 (2)\n",
      "I0705 01:52:34.230911   515 layer_factory.hpp:172] Creating layer 'softmax' of type 'Softmax'\n",
      "I0705 01:52:34.230928   515 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0705 01:52:34.230949   515 net.cpp:199] Created Layer softmax (23)\n",
      "I0705 01:52:34.230960   515 net.cpp:571] softmax <- fc8\n",
      "I0705 01:52:34.230967   515 net.cpp:541] softmax -> softmax\n",
      "I0705 01:52:34.231034   515 net.cpp:259] Setting up softmax\n",
      "I0705 01:52:34.231050   515 net.cpp:266] TEST Top shape for layer 23 'softmax' 1 2 (2)\n",
      "I0705 01:52:34.231060   515 net.cpp:337] softmax does not need backward computation.\n",
      "I0705 01:52:34.231071   515 net.cpp:337] fc8 does not need backward computation.\n",
      "I0705 01:52:34.231082   515 net.cpp:337] drop7 does not need backward computation.\n",
      "I0705 01:52:34.231093   515 net.cpp:337] relu7 does not need backward computation.\n",
      "I0705 01:52:34.231106   515 net.cpp:337] fc7 does not need backward computation.\n",
      "I0705 01:52:34.231122   515 net.cpp:337] drop6 does not need backward computation.\n",
      "I0705 01:52:34.231132   515 net.cpp:337] relu6 does not need backward computation.\n",
      "I0705 01:52:34.231143   515 net.cpp:337] fc6 does not need backward computation.\n",
      "I0705 01:52:34.231153   515 net.cpp:337] pool5 does not need backward computation.\n",
      "I0705 01:52:34.231171   515 net.cpp:337] relu5 does not need backward computation.\n",
      "I0705 01:52:34.231181   515 net.cpp:337] conv5 does not need backward computation.\n",
      "I0705 01:52:34.231197   515 net.cpp:337] relu4 does not need backward computation.\n",
      "I0705 01:52:34.231207   515 net.cpp:337] conv4 does not need backward computation.\n",
      "I0705 01:52:34.231217   515 net.cpp:337] relu3 does not need backward computation.\n",
      "I0705 01:52:34.231226   515 net.cpp:337] conv3 does not need backward computation.\n",
      "I0705 01:52:34.231243   515 net.cpp:337] pool2 does not need backward computation.\n",
      "I0705 01:52:34.231259   515 net.cpp:337] norm2 does not need backward computation.\n",
      "I0705 01:52:34.231269   515 net.cpp:337] relu2 does not need backward computation.\n",
      "I0705 01:52:34.231278   515 net.cpp:337] conv2 does not need backward computation.\n",
      "I0705 01:52:34.231297   515 net.cpp:337] pool1 does not need backward computation.\n",
      "I0705 01:52:34.231343   515 net.cpp:337] norm1 does not need backward computation.\n",
      "I0705 01:52:34.231354   515 net.cpp:337] relu1 does not need backward computation.\n",
      "I0705 01:52:34.231371   515 net.cpp:337] conv1 does not need backward computation.\n",
      "I0705 01:52:34.231384   515 net.cpp:337] input does not need backward computation.\n",
      "I0705 01:52:34.231392   515 net.cpp:379] This network produces output softmax\n",
      "I0705 01:52:34.231431   515 net.cpp:402] Top memory (TEST) required for data: 8315264 diff: 8315264\n",
      "I0705 01:52:34.231446   515 net.cpp:405] Bottom memory (TEST) required for data: 8315256 diff: 8315256\n",
      "I0705 01:52:34.231456   515 net.cpp:408] Shared (in-place) memory (TEST) by data: 2665856 diff: 2665856\n",
      "I0705 01:52:34.231467   515 net.cpp:411] Parameters memory (TEST) required for data: 227505672 diff: 227505672\n",
      "I0705 01:52:34.231483   515 net.cpp:414] Parameters shared memory (TEST) by data: 0 diff: 0\n",
      "I0705 01:52:34.231498   515 net.cpp:420] Network initialization done.\n",
      "I0705 01:52:34.342236   515 net.cpp:1129] Ignoring source layer train-data\n",
      "I0705 01:52:34.342281   515 net.cpp:1137] Copying source layer conv1 Type:Convolution #blobs=2\n",
      "I0705 01:52:34.342420   515 net.cpp:1137] Copying source layer relu1 Type:ReLU #blobs=0\n",
      "I0705 01:52:34.342439   515 net.cpp:1137] Copying source layer norm1 Type:LRN #blobs=0\n",
      "I0705 01:52:34.342453   515 net.cpp:1137] Copying source layer pool1 Type:Pooling #blobs=0\n",
      "I0705 01:52:34.342470   515 net.cpp:1137] Copying source layer conv2 Type:Convolution #blobs=2\n",
      "I0705 01:52:34.342675   515 net.cpp:1137] Copying source layer relu2 Type:ReLU #blobs=0\n",
      "I0705 01:52:34.342689   515 net.cpp:1137] Copying source layer norm2 Type:LRN #blobs=0\n",
      "I0705 01:52:34.342700   515 net.cpp:1137] Copying source layer pool2 Type:Pooling #blobs=0\n",
      "I0705 01:52:34.342707   515 net.cpp:1137] Copying source layer conv3 Type:Convolution #blobs=2\n",
      "I0705 01:52:34.343230   515 net.cpp:1137] Copying source layer relu3 Type:ReLU #blobs=0\n",
      "I0705 01:52:34.343245   515 net.cpp:1137] Copying source layer conv4 Type:Convolution #blobs=2\n",
      "I0705 01:52:34.343631   515 net.cpp:1137] Copying source layer relu4 Type:ReLU #blobs=0\n",
      "I0705 01:52:34.343649   515 net.cpp:1137] Copying source layer conv5 Type:Convolution #blobs=2\n",
      "I0705 01:52:34.343932   515 net.cpp:1137] Copying source layer relu5 Type:ReLU #blobs=0\n",
      "I0705 01:52:34.343946   515 net.cpp:1137] Copying source layer pool5 Type:Pooling #blobs=0\n",
      "I0705 01:52:34.343961   515 net.cpp:1137] Copying source layer fc6 Type:InnerProduct #blobs=2\n",
      "I0705 01:52:34.365063   515 net.cpp:1137] Copying source layer relu6 Type:ReLU #blobs=0\n",
      "I0705 01:52:34.365105   515 net.cpp:1137] Copying source layer drop6 Type:Dropout #blobs=0\n",
      "I0705 01:52:34.365123   515 net.cpp:1137] Copying source layer fc7 Type:InnerProduct #blobs=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0705 01:52:34.374724   515 net.cpp:1137] Copying source layer relu7 Type:ReLU #blobs=0\n",
      "I0705 01:52:34.374763   515 net.cpp:1137] Copying source layer drop7 Type:Dropout #blobs=0\n",
      "I0705 01:52:34.374769   515 net.cpp:1137] Copying source layer fc8 Type:InnerProduct #blobs=2\n",
      "I0705 01:52:34.374815   515 net.cpp:1129] Ignoring source layer loss\n",
      "not whale\n"
     ]
    }
   ],
   "source": [
    "!python submission.py '/dli/data/whale/data/train/not_face/w_1.jpg'  #This should return \"not whale\" at the very bottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caffe_output.log\t       snapshot_iter_2568.caffemodel\r\n",
      "deploy.prototxt\t\t       snapshot_iter_2675.caffemodel\r\n",
      "original.prototxt\t       snapshot_iter_2782.caffemodel\r\n",
      "snapshot_iter_107.caffemodel   snapshot_iter_2889.caffemodel\r\n",
      "snapshot_iter_1070.caffemodel  snapshot_iter_2996.caffemodel\r\n",
      "snapshot_iter_1177.caffemodel  snapshot_iter_3103.caffemodel\r\n",
      "snapshot_iter_1284.caffemodel  snapshot_iter_321.caffemodel\r\n",
      "snapshot_iter_1391.caffemodel  snapshot_iter_3210.caffemodel\r\n",
      "snapshot_iter_1498.caffemodel  snapshot_iter_3210.solverstate\r\n",
      "snapshot_iter_1605.caffemodel  snapshot_iter_428.caffemodel\r\n",
      "snapshot_iter_1712.caffemodel  snapshot_iter_535.caffemodel\r\n",
      "snapshot_iter_1819.caffemodel  snapshot_iter_642.caffemodel\r\n",
      "snapshot_iter_1926.caffemodel  snapshot_iter_749.caffemodel\r\n",
      "snapshot_iter_2033.caffemodel  snapshot_iter_856.caffemodel\r\n",
      "snapshot_iter_214.caffemodel   snapshot_iter_963.caffemodel\r\n",
      "snapshot_iter_2140.caffemodel  solver.prototxt\r\n",
      "snapshot_iter_2247.caffemodel  status.pickle\r\n",
      "snapshot_iter_2354.caffemodel  train_val.prototxt\r\n",
      "snapshot_iter_2461.caffemodel\r\n"
     ]
    }
   ],
   "source": [
    "!ls /dli/data/digits/20200705-005822-cea9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caffe_output.log\t       snapshot_iter_2268.caffemodel\r\n",
      "deploy.prototxt\t\t       snapshot_iter_2322.caffemodel\r\n",
      "original.prototxt\t       snapshot_iter_2376.caffemodel\r\n",
      "snapshot_iter_1026.caffemodel  snapshot_iter_2430.caffemodel\r\n",
      "snapshot_iter_108.caffemodel   snapshot_iter_2484.caffemodel\r\n",
      "snapshot_iter_1080.caffemodel  snapshot_iter_2538.caffemodel\r\n",
      "snapshot_iter_1134.caffemodel  snapshot_iter_2592.caffemodel\r\n",
      "snapshot_iter_1188.caffemodel  snapshot_iter_2646.caffemodel\r\n",
      "snapshot_iter_1242.caffemodel  snapshot_iter_270.caffemodel\r\n",
      "snapshot_iter_1296.caffemodel  snapshot_iter_2700.caffemodel\r\n",
      "snapshot_iter_1350.caffemodel  snapshot_iter_2700.solverstate\r\n",
      "snapshot_iter_1404.caffemodel  snapshot_iter_324.caffemodel\r\n",
      "snapshot_iter_1458.caffemodel  snapshot_iter_378.caffemodel\r\n",
      "snapshot_iter_1512.caffemodel  snapshot_iter_432.caffemodel\r\n",
      "snapshot_iter_1566.caffemodel  snapshot_iter_486.caffemodel\r\n",
      "snapshot_iter_162.caffemodel   snapshot_iter_54.caffemodel\r\n",
      "snapshot_iter_1620.caffemodel  snapshot_iter_540.caffemodel\r\n",
      "snapshot_iter_1674.caffemodel  snapshot_iter_594.caffemodel\r\n",
      "snapshot_iter_1728.caffemodel  snapshot_iter_648.caffemodel\r\n",
      "snapshot_iter_1782.caffemodel  snapshot_iter_702.caffemodel\r\n",
      "snapshot_iter_1836.caffemodel  snapshot_iter_756.caffemodel\r\n",
      "snapshot_iter_1890.caffemodel  snapshot_iter_810.caffemodel\r\n",
      "snapshot_iter_1944.caffemodel  snapshot_iter_864.caffemodel\r\n",
      "snapshot_iter_1998.caffemodel  snapshot_iter_918.caffemodel\r\n",
      "snapshot_iter_2052.caffemodel  snapshot_iter_972.caffemodel\r\n",
      "snapshot_iter_2106.caffemodel  solver.prototxt\r\n",
      "snapshot_iter_216.caffemodel   status.pickle\r\n",
      "snapshot_iter_2160.caffemodel  train_val.prototxt\r\n",
      "snapshot_iter_2214.caffemodel\r\n"
     ]
    }
   ],
   "source": [
    "!ls /dli/data/digits/20200705-013506-0df9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "Assessment1.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
